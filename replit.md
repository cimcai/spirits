# Philosophical Insight

## Overview

This is an AI-powered philosophical dialogue system where unlimited AI philosophers analyze live-generated conversations. Multiple AI philosophers display pulsing light indicators showing how confident they are about contributing wisdom. Users click the pulsing lights to insert the philosopher's insight into the conversation. The top 3 philosophers by effective confidence are dynamically mapped to keyboard shortcuts (1, 2, 3).

### Key Features
- **Pulsing Light Orbs**: Each AI philosopher displays a pulsing orb with size/intensity based on confidence (0-100% Value Score)
- **Confidence Decay**: Displayed confidence drops 15% per new message; button disappears below 50%
- **Confidence Multiplier**: User ratings adjust a per-philosopher multiplier (-1 rating = 0.8x penalty, +1 rating = 1.05x boost, capped at 0.1-1.5x)
- **Response Rating**: Thumbs up/down buttons appear after a philosopher speaks; adjusts confidence multiplier
- **User-Initiated Responses**: Click the orb or "Click to Speak" button to trigger the philosopher's response
- **Keyboard Shortcuts**: Press 1, 2, or 3 to trigger top-3 philosophers by effective confidence (for Ultimarc USB button integration)
- **Dynamic Top-3 Mapping**: Button indices (1, 2, 3) are dynamically assigned to the 3 philosophers with highest effective confidence
- **Text-to-Speech**: When triggered, philosophers speak their wisdom aloud with unique voices
- **Voice Toggle**: On/Off switch to enable/disable voice output (setting persisted in localStorage)
- **Most Insightful Today**: Displays the most recent philosophical insight triggered during the day
- **Unlimited Philosophers**: Create, configure, and manage any number of AI philosopher personas
- **Design**: Minimalist black and white UI; color used exclusively on pulsing philosopher orbs (rainbow gradient: red, violet, cyan)
- **AI-Generated Dialogue**: Live philosophical conversations generated by gpt-4o-mini between speakers Aiden, Mira, Leo, and Sage
- **Real-Time Analysis**: AI philosophers analyze conversations and determine when to contribute
- **Configuration System**: Edit philosopher name, description, persona, color, voice, and AI model
- **Live Audio Input**: Record microphone audio, auto-transcribe every 6s via gpt-4o-mini-transcribe, feed into conversation with configurable speaker labels (e.g., "Joscha Bach", "Interviewer"); speaker names persisted in localStorage
- **Ultimarc USB Button Integration**: API endpoint (`/api/led-status`) serves philosopher confidence as LED brightness (0-255); companion Python script (`ultimarc-led-controller.py`) polls and pulses Ultimarc PacLED64/Ultimate I/O button LEDs
- **Multi-Provider AI**: Philosophers can use OpenAI, Claude (Anthropic), DeepSeek, or Grok (OpenRouter) models
- **Inbound API for External Bots**: Open endpoints allow any clawdbot/AI agent to query the conversation stream (`GET /api/inbound/conversation`), check philosopher statuses (`GET /api/inbound/philosophers`), and submit responses (`POST /api/inbound/respond`)
- **Moltbook Integration**: Share philosopher insights to Moltbook social network for AI agents (`POST /api/moltbook/share-insight`); requires `MOLTBOOK_API_KEY` secret

## User Preferences

Preferred communication style: Simple, everyday language.

## System Architecture

### Frontend Architecture
- **Framework**: React 18 with TypeScript
- **Routing**: Wouter (lightweight React router)
- **State Management**: TanStack React Query for server state
- **UI Components**: shadcn/ui component library built on Radix UI primitives
- **Styling**: Tailwind CSS with CSS variables for theming (light/dark mode support)
- **Build Tool**: Vite with path aliases (@/ for client/src, @shared/ for shared)

### Backend Architecture
- **Framework**: Express.js 5 with TypeScript
- **Runtime**: Node.js with tsx for TypeScript execution
- **API Pattern**: RESTful JSON API under /api prefix
- **AI Integration**: OpenAI SDK configured via Replit AI Integrations (custom base URL and API key from environment variables)

### Data Storage
- **Database**: PostgreSQL via Drizzle ORM
- **Schema Location**: shared/schema.ts (shared between frontend and backend)
- **Migrations**: Drizzle Kit with migrations output to /migrations folder
- **Key Entities**:
  - `rooms`: Virtual conference rooms where conversations happen
  - `conversationEntries`: Text messages in a room (simulating transcribed audio)
  - `aiModels`: AI personas with trigger thresholds and personas
  - `modelAnalyses`: AI analysis results with confidence scores
  - `outboundCalls`: Triggered call records when AI decides to speak
  - `responseRatings`: User ratings (thumbs up/down) for philosopher responses with confidence multiplier impact
  - `latencyLogs`: Performance tracking for all AI operations (transcription, analysis, dialogue, TTS)
  - `users`: Basic user authentication table

### Build Configuration
- **Development**: `npm run dev` - runs tsx with Vite dev server middleware
- **Production Build**: Custom build script using esbuild for server, Vite for client
- **Output**: Server bundles to dist/index.cjs, client to dist/public

## External Dependencies

### AI Services
- **OpenAI API**: Used for conversation analysis, TTS, transcription via Replit AI Integrations
  - Environment variables: `AI_INTEGRATIONS_OPENAI_API_KEY`, `AI_INTEGRATIONS_OPENAI_BASE_URL`
  - Supports text chat completions, text-to-speech, speech-to-text, and image generation
- **Anthropic API**: Claude models via Replit AI Integrations
  - Environment variables: `AI_INTEGRATIONS_ANTHROPIC_API_KEY`, `AI_INTEGRATIONS_ANTHROPIC_BASE_URL`
- **OpenRouter API**: DeepSeek and Grok models via Replit AI Integrations
  - Environment variables: `AI_INTEGRATIONS_OPENROUTER_API_KEY`, `AI_INTEGRATIONS_OPENROUTER_BASE_URL`

### Database
- **PostgreSQL**: Required for data persistence
  - Environment variable: `DATABASE_URL`
  - Connection pooling via node-postgres (pg)

### Replit Integrations
The project includes pre-built integration modules in `server/replit_integrations/`:
- **audio/**: Voice chat with PCM16 streaming, speech-to-text, text-to-speech
- **chat/**: Conversation storage and streaming chat completions
- **image/**: Image generation via gpt-image-1 model
- **batch/**: Rate-limited batch processing utilities with retry logic

### Client Audio Utilities
Located in `client/replit_integrations/audio/`:
- AudioWorklet for streaming PCM16 playback
- React hooks for voice recording and streaming responses
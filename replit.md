# Philosophical Insight

## Overview

This is an AI-powered philosophical dialogue system where three AI philosophers analyze live-generated conversations. Multiple AI philosophers display pulsing light indicators showing how confident they are about contributing wisdom. Users click the pulsing lights to insert the philosopher's insight into the conversation.

### Key Features
- **Pulsing Light Orbs**: Each AI philosopher displays a pulsing orb with size/intensity based on confidence (0-100% Value Score)
- **Confidence Decay**: Displayed confidence drops 15% per new message; button disappears below 5%
- **User-Initiated Responses**: Click the orb or "Click to Speak" button to trigger the philosopher's response
- **Keyboard Shortcuts**: Press 1, 2, or 3 to trigger philosophers (for Ultimarc USB button integration)
- **Text-to-Speech**: When triggered, philosophers speak their wisdom aloud with unique voices
- **Three Philosophical Personas**: Stoic Philosopher (green/onyx voice), Existentialist Thinker (indigo/nova voice), Socratic Questioner (amber/echo voice)
- **AI-Generated Dialogue**: Live philosophical conversations generated by gpt-4o-mini between speakers Aiden, Mira, Leo, and Sage
- **Real-Time Analysis**: AI philosophers analyze conversations and determine when to contribute

## User Preferences

Preferred communication style: Simple, everyday language.

## System Architecture

### Frontend Architecture
- **Framework**: React 18 with TypeScript
- **Routing**: Wouter (lightweight React router)
- **State Management**: TanStack React Query for server state
- **UI Components**: shadcn/ui component library built on Radix UI primitives
- **Styling**: Tailwind CSS with CSS variables for theming (light/dark mode support)
- **Build Tool**: Vite with path aliases (@/ for client/src, @shared/ for shared)

### Backend Architecture
- **Framework**: Express.js 5 with TypeScript
- **Runtime**: Node.js with tsx for TypeScript execution
- **API Pattern**: RESTful JSON API under /api prefix
- **AI Integration**: OpenAI SDK configured via Replit AI Integrations (custom base URL and API key from environment variables)

### Data Storage
- **Database**: PostgreSQL via Drizzle ORM
- **Schema Location**: shared/schema.ts (shared between frontend and backend)
- **Migrations**: Drizzle Kit with migrations output to /migrations folder
- **Key Entities**:
  - `rooms`: Virtual conference rooms where conversations happen
  - `conversationEntries`: Text messages in a room (simulating transcribed audio)
  - `aiModels`: AI personas with trigger thresholds and personas
  - `modelAnalyses`: AI analysis results with confidence scores
  - `outboundCalls`: Triggered call records when AI decides to speak
  - `users`: Basic user authentication table

### Build Configuration
- **Development**: `npm run dev` - runs tsx with Vite dev server middleware
- **Production Build**: Custom build script using esbuild for server, Vite for client
- **Output**: Server bundles to dist/index.cjs, client to dist/public

## External Dependencies

### AI Services
- **OpenAI API**: Used for conversation analysis via Replit AI Integrations
  - Environment variables: `AI_INTEGRATIONS_OPENAI_API_KEY`, `AI_INTEGRATIONS_OPENAI_BASE_URL`
  - Supports text chat completions, text-to-speech, speech-to-text, and image generation

### Database
- **PostgreSQL**: Required for data persistence
  - Environment variable: `DATABASE_URL`
  - Connection pooling via node-postgres (pg)

### Replit Integrations
The project includes pre-built integration modules in `server/replit_integrations/`:
- **audio/**: Voice chat with PCM16 streaming, speech-to-text, text-to-speech
- **chat/**: Conversation storage and streaming chat completions
- **image/**: Image generation via gpt-image-1 model
- **batch/**: Rate-limited batch processing utilities with retry logic

### Client Audio Utilities
Located in `client/replit_integrations/audio/`:
- AudioWorklet for streaming PCM16 playback
- React hooks for voice recording and streaming responses